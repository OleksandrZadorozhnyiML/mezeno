---
title: "Creating the ``r params$package_name`` R package"
author: "O.Zadorozhnyi"
date: "The Date of the publication"
knit: litr::render
output: litr::litr_html_document
params:
  package_name: "mezen"
  package_parent_dir: "." # <-- relative to this file's location
---

<!-- This Rmd file contains all the code needed to define an R package.  Press "Knit" in RStudio or more generally run `litr::render("name-of-this-file.Rmd")` to generate the R package.  Remember that when you want to modify anything about the R package, you should modify this document rather than the package that is outputted.
-->

## Package setup

We start by specifying the information needed in the DESCRIPTION file of the R package.

```{r package-setup, message=FALSE, results='hide'}
usethis::create_package(
  path = ".",
  fields = list(
    Package = params$package_name,
    Version = "0.0.0.9000",
    Title = "A Package That analyses the metadata from Zenodo community",
    Description = "This package analyses metadata from Zenodo mardigmci community.",
    `Authors@R` = person(
      given = "Oleksandr",
      family = "Zadorozhnyi",
      email = "aleks.zadorozhnyi@gmail.com",
      role = c("aut", "cre")
      )
  )
)
usethis::use_mit_license(copyright_holder = "F. Last")
```

## Now to the package itself

### Define a function

Let's define a function for our R package:


```{r, warning=FALSE, message=FALSE}

# Loading Necessary packages 
library(litr)
library(zen4R)
library(tidyverse)
# packages to operate the json and html files
library(jsonlite)
library(RCurl)
# packages to transform text from html format to a machine readable format 
library(httr)
library(XML)
library(dplyr)
library(rvest)
library(stringr)# Load stringr package

# package to use the local ollama LLM
library(rollama)
library(tibble)

#my_token = "9hxUBkJtjtTeWAN1hIFMPrFHOG53vku0QdMeqrNXO113U7achzZ6drn4l4CB"
```


```{r}
#' Download the necessary files
#' 
#' @param name parameter that sets the name of the repository 
#' 
#' @export 
load_community_records <- function(name, exclamation = TRUE) {
  my_token = "9hxUBkJtjtTeWAN1hIFMPrFHOG53vku0QdMeqrNXO113U7achzZ6drn4l4CB"
  key_token = my_token
  zenodo = ZenodoManager$new(logger = "INFO",token = key_token)
  community_gm = zenodo$getCommunityById(name)
  community_records = community_gm$links$records  
  
  data = fromJSON(community_records)
  gmci_records_id = data$hits$hits$doi
  def=list(info = data, records= gmci_records_id)
  return(def)
}
```


```{r}
#' create dataframe with the information about the datasets in the community
#' 
#' 
#' 
#' @export 
create_dataframe <- function(){
  df = data.frame(
  ZenodoID = character(),  # Character data for description of the dataset, change accordingly
  CollectionName = character(),
  DOI = character(),
  Researchers = I(list()),
  License = character(),
  Keywords = I(list()),
  Url = character(),
  Downloads = integer(),
  Views = integer(),
  Number_of_features = I(list()),    # Number of features of the considered dataset, change accordingly
  Number_of_observations = I(list()),
  Ground_Truth = numeric(),    # Availability of the ground truth of the considered dataset, change accordingly
  Type_of_Graph = character(),
  Description = character(),
  Authors = I(list()),
  )
  colnames(df) = c("Number/ZenodoId","CollectionName","DOI","License","Keywords","Url","Downloads","Views","Number of features","Number of observations","Ground Truth","Type_of_Graph","Description","Authors/Creators")
  return(df) 
}
```

```{r}
#' 
#'
#' @param description_text the text of type string where the LLM has to find the findings 
#' @export
read_and_search <- function(description_text){
  
  message_features = paste("Q: What is the number of features? Return list of values")
  message_ground_truth = paste("Q: What is the ground truth of the graph? Return yes/no.")
  message_number_of_obs = paste("Q: What is the size of the dataset in the description? Return list of values.")
  message_type_of_graph = paste("Q: What is the type of graph of the dataset? If none return \"unknown. ")
  message_researchers = paste("Q: What are the authors in the references of the dataset. Return list of values.                               ")
  message_summary = paste("Q: Could you provide a summary of the description of the dataset? Return one sentence.")
  
  message_total = paste(message_features,message_ground_truth,message_number_of_obs,message_type_of_graph, message_researchers, message_summary, "Description of the dataset:",description_text)
  
  
q_set <- tribble(
  ~role, ~content,
  "system", "Reply to the questions. Search in the text after the words <<desciption of the dataset>>. If possible answer with only a number, yes/no or list of answers. If possible return list of outcomes.",
  "user",   message_total
)

}
```


```{r}
#' analyses the records within the given list of community records and extracts the metainformation from it
#' 
#' @param gmci_records_id Name of a person
#' 
#' @export 
#' 
analyse_records <- function(gmci_records_id){
  # A function which analyses the community records and fills in the information about the dataset. Manual part. 
    library(dplyr)
    my_token = "9hxUBkJtjtTeWAN1hIFMPrFHOG53vku0QdMeqrNXO113U7achzZ6drn4l4CB"
    key_token = my_token
    zenodo = ZenodoManager$new(logger = "INFO",token = key_token)
  
    numb_of_records = length(gmci_records_id)
    # create two dataframes to 
    json_data = list()
    json_description_data = list()
    
    # setting up the chatter 
    message_features = paste("Q: What is the number of features? Return list of   values")
    message_ground_truth = paste("Q: What is the ground truth of the graph? Return yes/no.")
    message_number_of_obs = paste("Q: What is the size of the dataset in the description? Return list of values.")
    message_type_of_graph = paste("Q: What is the type of graph of the dataset? If none return \"unknown. ")
    message_researchers = paste("Q: What are the authors in the references of the dataset. Return list of values.")
    message_description = paste("Q: Provide one sentence summary of the description of the dataset.")
    message_new = paste('Analyze description of the dataset. Answer the questions marked as Q:. As an output provide one json file in the following format:
                     [{ "Numb_of_features": value, "Ground_truth": value, "Size": value, "Type_of_graph": value, "Author_references": value/list of values, "One_sentence_description": value}]')


    
    for (item in 1:numb_of_records){
      # consider one record from the community   
        rec_curr = zenodo$getRecordByDOI(gmci_records_id[item])
         
         # extract list of subjects 
         subjects_vector = list(sapply(rec_curr$metadata$subjects, function(x) x$subject))
         # extract the list of creators of the dataset
         creator_names_vector = list(sapply(rec_curr$metadata$creators, function(x) x$person_or_org$name))
         # extract the id of the record of the dataset on zenodo
         zenodo_id = rec_curr$id
         # extract the doi of the records of the dataset on zenodo
         zenodo_doi = rec_curr$links$doi
         # extract the title of the record of the dataset on zenodo
         zenodo_title = rec_curr$metadata$title
         # store the license of the record of the dataset on zenodo
         zenodo_license_info = rec_curr$metadata$rights[[1]]$id
         # store the url under which the datasets is reachable
         zenodo_url = rec_curr$links$self
         # extract the information about the views and downloads of the record
         zenodo_uqviews = rec_curr$stats$this_version.unique_views
         zenodo_downlds = rec_curr$stats$this_version.unique_downloads
         license_title = rec_curr$metadata$rights[[1]]$title$en
         url_link = rec_curr$links$self
         
         
         
         # modifying the text for the to make it readable
         desc_info = rec_curr$metadata$description
                ### looking for a position of the number of features in the string ###
         # modifying the text to make it accesible for a LLM query
         u = read_html(desc_info)
         extracted_text = html_text(u)
         mod_text = gsub("\n"," ",extracted_text)
         mod_text = tolower(mod_text)
         
         # gathering the information into the list to put it inside the 
         
         
         
          message_total =   paste(message_new,message_features,message_ground_truth,message_number_of_obs,message_type_of_graph, message_researchers,message_description,"Description of the dataset:",mod_text)
         
          q_set <- tribble(
                            ~role, ~content,
                            "system", 'Answer the questions. If possible answer with only a number, yes/no or list of answers. If possible return list of outcomes for the value. Output NO other text, but one json file in the following format: [{ "Numb_of_features": value, "Ground_truth": value, "Size": value, "Type_of_graph": value, "Author_references": value/list of values, "One_sentence_description": value}]',
  "user",   message_total
)
          answer_curr = query(q_set,model_params = list(seed = 42, temperature = 0),model = "llama3.1")
          
          #new_entry = list(
          #                zenodoid = zenodo_id,
          #                title = zenodo_title,
          #                zenododoi = zenodo_doi,
          #                authors = I(creator_names_vector),
          #                license = license_title,
          #                keywords = I(subjects_vector),
          #                url = url_link,
          #                downloads = zenodo_downlds,
          #                views = zenodo_uqviews
        #)
        #json_data[[item]] = new_entry
         # work with the metadata description file: 
        
        
        
        
        
        # work with the operand returned by the values 
        new_entry_d = fromJSON(answer_curr$message$content)
        
        new_entry_d$title = zenodo_title
        new_entry_d$zenodoid = zenodo_id
        new_entry_d$zenododoi = zenodo_doi
        new_entry_d$authors = creator_names_vector
        new_entry_d$license = license_title
        new_entry_d$keywords = subjects_vector
        new_entry_d$url = url_link
        new_entry_d$downloads = zenodo_downlds
        new_entry_d$views = zenodo_uqviews
         
        # put another order between the variables
        desired_order <- c(
  "title", "zenodoid", "zenododoi", "authors", "license", "keywords", 
  "url", "downloads", "views", 
  "Numb_of_features", "Ground_truth", "Size", 
  "Type_of_graph", "Author_references", "One_sentence_description"
)

        # Reorder the columns in new_entry_d
        new_entry_d <- new_entry_d[desired_order]
        
        
        json_description_data[[item]] = new_entry_d 
         
         # forming up the query for the LLM ollama. notice: a running version of ollama should be open and              running locally on the device
         # Add one observation to the dataframe
   # new_observation <- data.frame(
   #                Name = curr_info$metadata$title,
   #                 Number_of_features = numb_of_features,
   #                  Ground_Truth = find_grnd_trth(mod_text),
   #                 DOI = curr_info$metadata$doi
   #                  Researchers
   # )
    }
    
    # now 
    
  # Convert lists to data frames
  #df1 = do.call(rbind, lapply(json_data, as.data.frame))
  #df2 = do.call(rbind, lapply(json_description_data, as.data.frame))
  
  # Perform a left join based on the 'name' column
  #merged_df = left_join(df1, df2, by = "title")  
  #merged_list = lapply(1:nrow(merged_df), function(i) merged_df[i, ])
  
  json_data = toJSON(json_description_data, pretty = TRUE)  # 'pretty = TRUE'     makes it more readable
  write(json_data, file = "example.json")
  return(json_description_data)
    
}
```

Code chunks whose first line starts with `#'` are added to the package.

```{r}
#'@param name path to the file which 
#' 
#' @export 
show <- function(name){
  json_data <- fromJSON(name)
  
  # Print the information in a readable format
  print("Information stored in JSON file:")
  print(json_data)
}
```


```{r sample_code, echo=FALSE, message=FALSE, warning=FALSE}
data = load_community_records("mardigmci")
file = analyse_records(data$records[1:2])
show("example.json")
```


```{r question_function, message=FALSE, warning=FALSE, include=FALSE}
question <- function(question_text,json_file="example.json"){
  text_pre = "Answer the question based only on the input of the following json file.  As output use only text from the json file and nothing else. If thereis nothing to output, return <>. Json File:"
  json_data <- fromJSON(json_file)
  # Convert JSON data to a text format (pretty-printed)
  text_data <- toJSON(json_data, pretty = TRUE, auto_unbox = TRUE)
  line = paste(text_pre,text_data,"Question:",question_text)
  
  
  
  q_set <- tribble(
                            ~role, ~content,
                            "system", 'Answer the question based only on the input of the json file. As output use only text from the json file. As output use only text from the json file and nothing else. If thereis nothing to output, return <>',
                            "user",   line
                   )
  
  query(q_set,model_params = list(seed = 42, temperature = 0),model = "llama3.1" )
}
```


That code chunk does not start with `#'`, so it is not added to the package. The following chunk code demonstrates how the questions can be put and what answers the LLM gives to it:
```{r}
question("What datasets have keywords 'Count data'? Return their titles.", json_data)


question("What datasets have more than 10 features? Return their zenodoids.")

question("What datasets have more than 100 views? Return their titles.")


```


```{r}
#create a folder where to download my files
dir.create("download_zenodo")
options(timeout = 120)
#download files with shortcut function 'download_zenodo'
download_zenodo(path = "download_zenodo", "https://doi.org/10.5281/zenodo.8063512",timeout = 180)
downloaded_files <- list.files("download_zenodo")
```
Let's write some tests to make sure the function behaves as desired:

```{r}
testthat::test_that("analyse records works", {
  testthat::expect_equal(say_hello("Jacob"), "Hello Jacob!")
  testthat::expect_equal(say_hello("Jacob", exclamation = FALSE), "Hello Jacob.")
})
```

Code chunks that have one or more lines starting with `test_that(` (or `testthat::test_that(`) are added to the package as tests.

## Documenting the package and building

We finish by running commands that will document, build, and install the package.  It may also be a good idea to check the package from within this file.

```{r}
litr::document() # <-- use instead of devtools::document()
# devtools::build()
# devtools::install()
# devtools::check(document = FALSE)
```

